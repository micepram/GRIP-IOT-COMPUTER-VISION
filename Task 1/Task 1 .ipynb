{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6d2dc2d",
   "metadata": {},
   "source": [
    "# Object Detection Using MobileNet & SSD- Graduate Rotational Internship Program\n",
    "\n",
    "## IoT & Computer Vision- Task 1 \n",
    "\n",
    "### Pramika Garg\n",
    "#### [Linkedln](https://www.linkedin.com/in/micepram/)   [Github](https://github.com/micepram)\n",
    "\n",
    "\n",
    "\n",
    "Object detection, a subset of computer vision, is an automated method for locating interesting objects in an image with respect to the background. Solving the object detection problem means placing a tight bounding box around these objects and associating the correct object category with each bounding box. Like other computer vision tasks, deep learning is the state-of-art method to perform object detection. MobileNet is an efficient and portable CNN architecture that is used in real world applications. MobileNets primarily use depthwise seperable convolutions in place of the standard convolutions used in earlier architectures to build lighter models. Single Shot Detector's are used to ensure one shot can detect multiple objects, for example YOLO.\n",
    "\n",
    "In the current task, we shall utilise MobileNetSSD with a DNN Module in OpenCV to build our object detection system.\\\n",
    "Reference: [Object detection with deep learning and OpenCV - PyImageSearch](https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f69a5",
   "metadata": {},
   "source": [
    "### Step 1 - Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa89101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10570825",
   "metadata": {},
   "source": [
    "### Step 2 - Initialization of Different Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f65204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a set of bounding box colors for each class that was used to train MobileNet\n",
    "\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "\"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63844f6a",
   "metadata": {},
   "source": [
    "### Step 3 - Loading Pre-Trained Model & Images for Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcf077f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = cv2.dnn.readNetFromCaffe('MobileNetSSD_deployprototxt.txt','MobileNetSSD_deploy.caffemodel')\n",
    "img = cv2.imread('imgs/multi2.jpg')\n",
    "img= cv2.resize(img, (500, 500))\n",
    "cv2.imshow(\"Detected\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ac37c",
   "metadata": {},
   "source": [
    "### Step 4 - Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8837f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Dimensions & Creating 500x500 Blob, then passing it to the DNN\n",
    "\n",
    "(h, w) = img.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(img, 0.007843,(500, 500), 127.5)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a860b4",
   "metadata": {},
   "source": [
    "### Step 5 - Labelling Predictions, Boxing Objects & Printing the Probability  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6086574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus: 62.21%\n",
      "car: 95.73%\n",
      "car: 88.33%\n",
      "car: 84.30%\n",
      "car: 67.17%\n",
      "person: 90.08%\n",
      "sofa: 44.17%\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0, detections.shape[2]):\n",
    "    \n",
    "    # Extracting Confidence\n",
    "    \n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    \n",
    "    # Filtering Confidence with minimum 30%\n",
    "    \n",
    "    if confidence > 0.3 :\n",
    "        \n",
    "        # Extracting Index of Class Label & Computing Dimensions of the Bounding Box\n",
    "        \n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        \n",
    "        # Displaying the Probability\n",
    "        \n",
    "        label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "        print(\"{}\".format(label))\n",
    "        cv2.rectangle(img, (startX, startY), (endX, endY), COLORS[idx], 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        cv2.putText(img, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b4697",
   "metadata": {},
   "source": [
    "### Step 6 - Displaying the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989a44b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Output\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96c7d9",
   "metadata": {},
   "source": [
    "### Step 7 -  Detecting the Output from Input Using Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0717dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(imgloc):\n",
    "    img = cv2.imread(\"imgs/\" + imgloc)\n",
    "    img = cv2.resize(img, (500, 500))\n",
    "    cv2.imshow(\"The Input: \", img)\n",
    "    cv2.waitKey(0)\n",
    "    (h, w) = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.007843,(200, 200), 127.5)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.3:\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "            print(\"{}\".format(label))\n",
    "            cv2.rectangle(img, (startX, startY), (endX, endY), COLORS[idx], 2)\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(img, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "    cv2.imshow(\"The Output:\", img)\n",
    "    cv2.waitKey(0)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade2c2b",
   "metadata": {},
   "source": [
    "### Step 8 - Displaying the Output Image and Testing the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae699a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars.jpg:\n",
      "car: 98.25%\n",
      "car: 97.88%\n",
      "dhs.jsp:\n",
      "cow: 80.88%\n",
      "horse: 87.26%\n",
      "sheep: 88.77%\n",
      "dp.jpg\n",
      "dog: 93.14%\n",
      "person: 90.88%\n",
      "horse.jpg:\n",
      "horse: 99.78%\n",
      "horse: 49.49%\n",
      "multi1.jpg:\n",
      "bus: 84.16%\n",
      "chair: 33.15%\n",
      "person: 68.81%\n",
      "person: 63.49%\n",
      "person: 35.85%\n",
      "multi2.jpg:\n",
      "bus: 88.80%\n",
      "car: 93.83%\n",
      "car: 35.76%\n",
      "car: 33.60%\n"
     ]
    }
   ],
   "source": [
    "print('cars.jpg:')\n",
    "detect_object('cars.jpg')\n",
    "print('dhs.jsp:')\n",
    "detect_object('dhs.jpg')\n",
    "print('dp.jpg')\n",
    "detect_object('dp.jpg')\n",
    "print('horse.jpg:')\n",
    "detect_object('horse.jpg')\n",
    "print('multi1.jpg:')\n",
    "detect_object('multi1.jpg')\n",
    "print('multi2.jpg:')\n",
    "detect_object('multi2.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
